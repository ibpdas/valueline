<p align="center">
  <a href="https://ibpdas.github.io/data-strategy-impact-dashboard/" target="_blank">
    <img src="https://img.shields.io/badge/Open%20Dashboard-Live%20Demo-blue?style=for-the-badge" alt="Dashboard Link">
  </a>
</p>

<h1 align="center">ValueLine: A Clearer Line of Sight from Data to Impact</h1>

<p align="center">
  A three level causal model to help public sector data leaders explain, track and demonstrate 
  data strategy impact in complex or federated organisations.
</p>

---

## ðŸ§­ Quick navigation

- [Concept in 30 seconds](#-concept-in-30-seconds)
- [1. What the model solves](#1-what-the-model-solves)
- [2. The three levels at a glance](#2-the-three-levels-at-a-glance)
- [3. Leading, signal and lagging indicators](#3-leading-signal-and-lagging-indicators)
- [4. Executive decision box](#4-executive-decision-box)
- [5. Measurement methods](#5-measurement-methods)
- [6. Why this model works](#6-why-this-model-works)
- [7. How the model is used](#7-how-the-model-is-used)
- [8. What this repository provides](#8-what-this-repository-provides)
- [9. Status](#9-status)
- [10. Limitations](#10-limitations)
- [11. Contributing and reuse](#11-contributing-and-reuse)
- [12. Motivation for ValueLine](#12-motivation-for-valueline)

---

## ðŸ“Œ Concept in 30 seconds

Data teams often deliver essential foundational work, but leaders struggle to see how that effort translates into maturity or measurable outcomes.  

**ValueLine** makes that connection visible by mapping foundations â†’ maturity â†’ impact in a single, repeatable model.

It grew out of years of seeing talented teams do the right things but struggle to tell a clear value story.  

**ValueLine** exists to give them a practical way to explain progress, set realistic expectations and focus attention on what truly drives public value.

It shifts conversations from _â€œWhy is value slow?â€_ to _â€œWhich conditions and decisions will deliver value now, next and later?â€_

---

## 1. What the model solves

Most public sector organisations struggle to show how data strategy activity leads to maturity and, ultimately, to outcomes and impact.

The core challenge is **attribution**: data teams influence the inputs but not the outcomes or the speed at which they emerge.

**ValueLine** structures the story into three causal levels. Each works on a different time horizon and with different types of indicators, helping leaders understand:

- where value can be realised quickly  
- where it takes longer  
- which decisions accelerate progress  

### Caveat â€“ scope and boundaries

This dashboard focuses on the direct and near-term effects of organisational data strategy work.

It shows how foundational activity strengthens system conditions and maturity over time, but it does **not** capture every form of value generated by a data ecosystem.

- It is **not** a full data valuation framework and does not estimate wider social, environmental or economic value.  
- It is **not** designed for sector-wide or national data strategies, where scale, incentives and value mechanisms differ significantly.

### Regulatory obligations vs strategic value

Many teams manage data well for compliance, audit or legal requirements. Compliance protects integrity and reduces risk, but it is **not the same as value**.

Strategy work focuses on the conditions that enable reuse, connection and translation of data into maturity improvements and future outcomes.

---

## 2. The three levels at a glance

### Level 1. Foundational enabler shift

Early conditions shaped by data leaders and partner teams. Typical shifts include moving from:

- **Strategy** â€“ isolated priorities â†’ shared direction and cross-cutting data priorities  
- **Leadership** â€“ â€œtheir data problemâ€ â†’ shared ownership and accountability  
- **Foundation** â€“ fragmented fixes â†’ common policies, platforms and standards  
- **Community** â€“ pockets of innovation â†’ shared practice and reusable capabilities  
- **Engagement** â€“ ad-hoc conversations â†’ ongoing cross-functional, cross-organisational engagement  

### Level 2. Maturity shift

Describes how the organisation behaves when Level 1 foundations begin to take effect, using the six themes from the **Data Maturity Assessment for Government (2023)**:

- **Uses** â€“ from reactive reporting â†’ proactive operational and strategic use  
- **Data** â€“ from siloed and inconsistent â†’ coherent, reusable, governed and interoperable  
- **Leadership** â€“ from passive or detached â†’ active sponsorship and expectation-setting  
- **Culture** â€“ from sporadic and low-confidence â†’ everyday data-informed decisions  
- **Tools** â€“ from fragmented â†’ integrated, discoverable and self-service  
- **Skills** â€“ from pockets of expertise â†’ widespread literacy and continuous development  

### Level 3. Outcome and impact shift

As Level 1 and Level 2 strengthen, public value shifts in predictable ways:

- **Financial savings** â€“ isolated wins â†’ sustained, organisation-wide efficiencies  
- **User satisfaction** â€“ anecdotal â†’ measurable, repeatable improvements  
- **Efficiency gains** â€“ local wins â†’ system wide improvements in core processes  
- **Time savings** â€“ task based â†’ end to end workflow optimisation  
- **Public good impact** â€“ occasional â†’ continuous contributions to policy and service outcomes  

---

## 3. Leading, signal and lagging indicators

Expectations are set realistically by classifying metrics as:

- **Leading** â€“ early signs that enablers are working (mainly Level 1)  
- **Signal** â€“ system response and behaviour change (mainly Level 2)  
- **Lagging** â€“ measurable outcomes and public value (mainly Level 3)  

This explains why different results move at different speeds.

> **Important: different results move at different speeds**
>
> - **Financial savings** from removing duplicate systems, rationalising platforms or tightening licensing and procurement can move quickly once Level 1 strategic alignment and leadership decisions are in place.  
> - **Efficiency gains and time savings** typically move at a medium pace as teams improve data quality, adopt shared tools and reuse common assets.  
> - **User satisfaction** tends to move more slowly because it depends on behaviour, trust and consistent adoption across many teams.  
> - **Public good impact** takes longest to show because it relies on whole-system alignment and sustained use of evidence over time.  
>
> **ValueLine** model makes these pacing differences explicit so expectations stay realistic.

---

## 4. Executive decision box

The dashboard includes an **Executive decision box** to the right of Page 1.

It gives leaders a focused view of:

- top three asks  
- key trade offs  
- critical dependencies  
- confidence levels in the evidence  
- forward look priorities  

This turns data strategy into **specific executive actions**, not just a performance commentary.

---

## 5. Measurement methods

**ValueLine** uses a **mixed method** approach to understand capability building and value creation.  
The labels (Leading, Signal, Lagging) show which part of the causal chain each method mainly informs.

### Quantitative
- monthly performance reports (Lagging)
- quarterly senior leadership updates (Signal)
- validated cost and time savings (Lagging)
- adoption of policies and standards (Leading)
- dataset and model reuse (Signal)
- API and open data analytics (Signal)
- CO2 impacts from compute and storage (Lagging)

### Qualitative 
- staff surveys (Signal)
- training and community participation (Leading)
- user research and engagement logs (Signal)
- case studies and reuse stories (Lagging)

### Economic and experimental methods
- Benefit Cost Ratio (BCR) (Lagging)
- Net Present Value (NPV) (Lagging)
- experimental or counterfactual methods (Lagging)

Together these create a rounded view of capability building and value creation.

---

## 6. Why this model works

**ValueLine** is grounded in a simple systems principle:  
> foundations shape maturity, and maturity shapes outcomes and impact.

This works because:

- foundational and outcome changes move at different speeds  
- system behaviour lags behind system investment  
- maturity cannot exceed the strength of foundations  
- outcomes cannot exceed maturity  
- value emerges from alignment, not isolated effort  
- progress is iterative, not linear  
- no magic metric and mixed method evaluation for rounded storytelling 

These principles justify the structure of the dashboard and the use of leading, signal and lagging indicators.

---

## 7. How the model is used

**ValueLine** helps data teams:

- explain data strategy impact in a holistic way 
- engage senior leaders with more confidence  
- identify where to invest next in **Level 1** (conditions) or **Level 2** (maturity)  
- align directorates or ALBs within federated departments without turning it into a league table  

It is particularly useful for:

- CDO and data leadership teams  
- portfolio, PMO and governance groups  
- strategy, policy and finance partners  
- performance, evaluation and benefits leads  

---

## 8. What this repository provides

- HTML conceptual dashboard  
- methodology notes, metric catalogue and theory of change  
- Excel input template  
- PowerPoint generator script for board packs  
- Light-touch architecture notes  
- Synthetic example datasets  

---

## 9. Status

- âœ… HTML conceptual dashboard  
- ðŸŸ¡ Excel template (MVP)  
- ðŸŸ¡ PowerPoint generator (MVP)  
- ðŸŸ¡ Power BI template (MVP)  
- â¬œ Streamlit app (future)  

---

## 10. Limitations

- All data is **synthetic**  
- The dashboard is a **learning and facilitation tool**, not an official scorecard  
- It is not a benchmark, standard or assurance framework  
- Attribution remains approximate  
- Evidence quality varies and improves over time  
- Outcomes and impact can lag by years  
- Maturity scores are directional, not absolute  
- Real decisions should always rely on your own evidence, governance and professional judgement  

---

## 11. Contributing and reuse

You are welcome to:

- fork and customise  
- propose improvements via issues or pull requests  
- share alternative layouts or metrics that help other public-sector teams  

Attribution is optional but appreciated.

---

## 12. Motivation for ValueLine

**ValueLine** grew out of years of leading data strategy work in complex, federated environments.

Again and again I saw dedicated teams doing the right work, but struggling to show progress because the signals and measurements were unclear. Across many conversations with colleagues, and after reviewing more than fifty data strategies and business cases, the same pattern kept appearing:

> Strong foundational work was happening, but the story of progress was difficult to explain.  
> Expectations drifted, value signals came too late, and the connection between foundations, maturity and outcomes was often lost.

I built **ValueLine** as a practical and repeatable way to make that connection clearer.  
It reflects trial and error, small breakthroughs and generous advice from others along the way.

If it helps even a few people and teams focus on what matters and explain their impact with more clarity, it will have done its job.

â€” **Bandhu P. Das**

<p align="center">
  <a href="https://www.brighttalk.com/webcast/12405/602410" target="_blank">
    <img src="https://img.shields.io/badge/Talk-Unlocking%20the%20Value%20of%20Data-blue?style=flat-square" alt="Talk: Unlocking the Value of Data" />
  </a>
</p>